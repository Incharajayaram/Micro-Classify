{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 3_long_blade_rotor\n",
      "Probability: 1.1630\n",
      "Inference Time: 0.0039 seconds\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "\n",
    "# Load the ONNX model\n",
    "model_path = \"custom_cnn.onnx\"\n",
    "session = ort.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "# Get input and output information\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "input_shape = session.get_inputs()[0].shape\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "])\n",
    "\n",
    "# Define the six classes\n",
    "classes = [\"3_long_blade_rotor\", \"3_short_blade_rotor\", \"Bird\", \"Bird+mini-helicopter\", \"drone\", \"rc_plane\"]\n",
    "\n",
    "# Load an image (replace with the path to your image)\n",
    "image_path = \"D:/Micro-Classify/ml_model/notebooks/DIAT-uSAT_dataset/3_long_blade_rotor/figure1.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Apply the transformations\n",
    "image = Image.open(image_path)\n",
    "input_tensor = transform(image)\n",
    "\n",
    "# Add a batch dimension\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "# Convert to NumPy array with correct data type\n",
    "input_array = input_tensor.numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "# Start timer for inference\n",
    "start_time = time.time()\n",
    "\n",
    "# Run the inference\n",
    "output = session.run([output_name], {input_name: input_array})\n",
    "\n",
    "# End timer for inference\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate inference time\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "# Process the output\n",
    "output_probabilities = np.squeeze(output[0])  # Remove unnecessary dimensions\n",
    "predicted_class = np.argmax(output_probabilities)  # Get index of the highest probability\n",
    "\n",
    "# Display results\n",
    "print(f\"Predicted Class: {classes[predicted_class]}\")\n",
    "print(f\"Probability: {output_probabilities[predicted_class]:.4f}\")\n",
    "print(f\"Inference Time: {inference_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "  3_long_blade_rotor     0.9834    0.9625    0.9728       799\n",
      " 3_short_blade_rotor     0.9604    0.9712    0.9658       800\n",
      "                Bird     1.0000    1.0000    1.0000       800\n",
      "Bird+mini-helicopter     0.9975    0.9730    0.9851       815\n",
      "               drone     1.0000    1.0000    1.0000       835\n",
      "            rc_plane     0.9626    0.9962    0.9791       800\n",
      "\n",
      "            accuracy                         0.9839      4849\n",
      "           macro avg     0.9840    0.9838    0.9838      4849\n",
      "        weighted avg     0.9841    0.9839    0.9839      4849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the ONNX model\n",
    "model_path = \"custom_cnn.onnx\"\n",
    "session = ort.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "# Get input and output information\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "])\n",
    "\n",
    "# Define the six classes\n",
    "classes = [\"3_long_blade_rotor\", \"3_short_blade_rotor\", \"Bird\", \"Bird+mini-helicopter\", \"drone\", \"rc_plane\"]\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess an image for model inference\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    input_tensor = transform(image)\n",
    "    input_tensor = input_tensor.unsqueeze(0)\n",
    "    return input_tensor.numpy().astype(np.float32)\n",
    "\n",
    "def predict_image(session, input_array, input_name, output_name):\n",
    "    \"\"\"\n",
    "    Run inference on a single image\n",
    "    \"\"\"\n",
    "    output = session.run([output_name], {input_name: input_array})\n",
    "    output_probabilities = np.squeeze(output[0])\n",
    "    return np.argmax(output_probabilities)\n",
    "\n",
    "def evaluate_model(dataset_root):\n",
    "    \"\"\"\n",
    "    Evaluate the ONNX model and generate classification report\n",
    "    \n",
    "    :param dataset_root: Root directory containing subdirectories for each class\n",
    "    :return: Tuple of (true labels, predicted labels)\n",
    "    \"\"\"\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    # Iterate through each class directory\n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(dataset_root, class_name)\n",
    "        \n",
    "        # Check if directory exists\n",
    "        if not os.path.isdir(class_path):\n",
    "            print(f\"Warning: Directory {class_path} does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        # Process each image in the class directory\n",
    "        for image_filename in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_filename)\n",
    "            \n",
    "            try:\n",
    "                # Preprocess the image\n",
    "                input_array = preprocess_image(image_path)\n",
    "                \n",
    "                # Predict the class\n",
    "                predicted_class = predict_image(session, input_array, input_name, output_name)\n",
    "                \n",
    "                # Store true and predicted labels\n",
    "                true_labels.append(class_idx)\n",
    "                predicted_labels.append(predicted_class)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "    \n",
    "    return true_labels, predicted_labels\n",
    "\n",
    "def generate_classification_report(dataset_root):\n",
    "    \"\"\"\n",
    "    Generate and print classification report\n",
    "    \n",
    "    :param dataset_root: Root directory containing subdirectories for each class\n",
    "    \"\"\"\n",
    "    # Evaluate the model\n",
    "    true_labels, predicted_labels = evaluate_model(dataset_root)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(\n",
    "        true_labels, \n",
    "        predicted_labels, \n",
    "        target_names=classes, \n",
    "        digits=4\n",
    "    )\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    \n",
    "    # Create confusion matrix with Matplotlib\n",
    "    im = plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar(im)\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xticks(range(len(classes)), classes, rotation=45)\n",
    "    plt.yticks(range(len(classes)), classes)\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "# Usage\n",
    "# Replace with the path to your test dataset root directory\n",
    "dataset_root = \"D:/Micro-Classify/ml_model/notebooks/DIAT-uSAT_dataset\"\n",
    "generate_classification_report(dataset_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
